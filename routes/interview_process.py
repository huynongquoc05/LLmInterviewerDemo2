# routes/interview_process.py
"""
Routes x·ª≠ l√Ω ti·∫øn tr√¨nh ph·ªèng v·∫•n (start, answer, resume)
"""

import re
from dataclasses import asdict
from datetime import datetime
from flask import Blueprint, jsonify, request
from bson import ObjectId
from langchain_community.vectorstores import FAISS

from config import Config
from extensions import (
    db_batches, db_records,
    embedding_manager, interview_processor, context_cache
)
from utils import to_mongo_safe, to_json_safe
from routes.audio import create_audio_from_text
from LLMInterviewer4 import (
    InterviewConfig, InterviewContext, InterviewRecord,
    classify_level_from_score, Level, QuestionDifficulty,
    InterviewPhase, QuestionAttempt
)

interview_bp = Blueprint('interview', __name__)


def get_base_path():
    return '/iview1' if 'fit.neu.edu.vn' in request.host else ''


# routes/interview_process.py (th√™m v√†o ƒë·∫ßu file)

from flask import session  # ‚Üê Th√™m import


def get_current_user_id():
    """L·∫•y user_id t·ª´ session"""
    user = session.get('user')
    if not user:
        return None
    return user.get('id')


def require_auth():
    """Ki·ªÉm tra user ƒë√£ login ch∆∞a"""
    if not session.get('user'):
        return jsonify({
            "success": False,
            "error": "Unauthorized - Please login",
            "redirect": "/login"
        }), 401
    return None


def verify_batch_ownership(batch_id: str, user_id: int):
    """Ki·ªÉm tra user c√≥ quy·ªÅn truy c·∫≠p batch n√†y kh√¥ng"""
    from extensions import db_batches
    batch = db_batches.find_one({"_id": ObjectId(batch_id)})

    if not batch:
        return False

    return batch.get("user_id") == user_id
# ===================================================================
# Context Wakeup (Cache)
# ===================================================================
def wakeup_context(batch_id: str):
    """
    Load context cho batch (cached ƒë·ªÉ t√°i s·ª≠ d·ª•ng)
    Returns: (cv_db, context)
    """
    if batch_id in context_cache:
        return context_cache[batch_id]

    batch_info = db_batches.find_one({"_id": ObjectId(batch_id)})
    if not batch_info:
        raise ValueError(f"Kh√¥ng t√¨m th·∫•y batch ID: {batch_id}")

    # Load embedding model (cached)
    embedding_model = embedding_manager.get_model(batch_info["embedding_model_name"])

    # Load CV vectorstore
    cv_db = FAISS.load_local(
        batch_info["cv_vectorstore_path"],
        embedding_model,
        allow_dangerous_deserialization=True
    )

    # Build context
    context = InterviewContext(
        topic=batch_info["topic"],
        outline=batch_info["outline"],
        knowledge_text=batch_info["knowledge_text"],
        outline_summary=batch_info["knowledge_summary"],
        config=InterviewConfig(**batch_info["config"])
    )

    # Cache it
    context_cache[batch_id] = (cv_db, context)
    print(f"‚ö° Cache context cho batch {batch_id} (topic: {batch_info['topic']})")

    return cv_db, context


# ===================================================================
# Start/Resume Interview
# ===================================================================
@interview_bp.route("/start_candidate", methods=["POST"])
def start_candidate_interview():
    """
    B·∫Øt ƒë·∫ßu ho·∫∑c ti·∫øp t·ª•c ph·ªèng v·∫•n
    """
    auth_error = require_auth()
    if auth_error:
        return auth_error

    user_id = get_current_user_id()

    try:
        data = request.json
        batch_id = data["session_id"]
        candidate_name = data["candidate_name"]  # ‚úÖ Ch·ªâ c·∫ßn t√™n

        # ‚úÖ THAY ƒê·ªîI: Kh√¥ng verify ownership c·ªßa batch
        if not verify_batch_ownership(batch_id, user_id):
            return jsonify({
                "success": False,
                "error": "Permission denied - You can only access your own interview batches"
            }), 403

        # ‚úÖ B∆Ø·ªöC 1: T√¨m record ƒë√£ t·ªìn t·∫°i (d√πng candidate_name tr·ª±c ti·∫øp)
        existing_record = db_records.find_one({
            "batch_id": batch_id,
            "candidate_name": candidate_name  # ‚úÖ Kh√¥ng c·∫ßn th√™m class
        })

        # ‚úÖ B∆Ø·ªöC 2: N·∫øu ƒë√£ ho√†n th√†nh ‚Üí Tr·∫£ v·ªÅ summary
        if existing_record and existing_record.get("is_finished"):
            return jsonify({
                "success": True,
                "already_completed": True,
                "record_id": str(existing_record["_id"]),
                "summary": {
                    "candidate_info": {
                        "name": candidate_name,  # ‚úÖ Ch·ªâ t√™n
                        "classified_level": existing_record.get("classified_level", "")
                    },
                    "interview_stats": {
                        "final_score": existing_record.get("final_score", 0),
                        "total_questions": existing_record.get("total_questions_asked", 0),
                        "timestamp": existing_record.get("created_at", "")
                    },
                    "question_history": [
                        {
                            "question_number": idx + 1,
                            "difficulty": q["difficulty"],
                            "question": q["question"],
                            "answer": q["answer"],
                            "score": q["score"],
                            "analysis": q["analysis"],
                            "time_limit": q.get("time_limit", 60),
                            "time_spent": q.get("time_spent", 0)
                        }
                        for idx, q in enumerate(existing_record.get("history", []))
                    ]
                }
            })

        # ‚úÖ B∆Ø·ªöC 3-6: Wakeup context & t·∫°o record m·ªõi
        cv_db, context = wakeup_context(batch_id)

        # ‚úÖ Query CV vectorstore b·∫±ng t√™n tr·ª±c ti·∫øp
        profile_docs = cv_db.similarity_search(candidate_name, k=1)
        if not profile_docs:
            return jsonify({"error": f"Kh√¥ng t√¨m th·∫•y h·ªì s∆° {candidate_name}"}), 404

        profile_text = profile_docs[0].page_content

        # ‚úÖ Classify level t·ª´ ƒëi·ªÉm
        score_match = re.search(r'ƒêi·ªÉm 40%[:\s]+([0-9.]+)', profile_text)
        level = classify_level_from_score(float(score_match.group(1))) if score_match else Level.TRUNG_BINH

        # ‚úÖ T·∫°o record m·ªõi
        new_record, first_q_data = interview_processor.start_new_record(
            batch_id,
            candidate_name,  # ‚úÖ Ch·ªâ c·∫ßn t√™n
            profile_text,
            level,
            context
        )

        record_dict = to_mongo_safe(asdict(new_record))

        if existing_record:
            record_dict["created_at"] = existing_record.get("created_at")
            record_dict["reset_count"] = existing_record.get("reset_count", 0) + 1
            record_dict["last_reset_at"] = datetime.utcnow().isoformat()

            db_records.replace_one(
                {"_id": existing_record["_id"]},
                record_dict
            )
            record_id = str(existing_record["_id"])
            print(f"üîÑ Reset record cho {candidate_name} (l·∫ßn {record_dict['reset_count']})")
        else:
            result = db_records.insert_one(record_dict)
            record_id = str(result.inserted_id)
            print(f"üÜï T·∫°o record m·ªõi cho {candidate_name}")

        # ‚úÖ T·∫°o audio
        audio_id = create_audio_from_text(first_q_data["question"])

        return jsonify({
            "success": True,
            "already_completed": False,
            "record_id": record_id,
            "question": first_q_data["question"],
            "difficulty": first_q_data["difficulty"],
            "time_limit": first_q_data["time_limit"],
            "level": level.value,
            "phase": "warmup",
            "audio_id": audio_id,
            "audio_url": f"{get_base_path()}/audio/{audio_id}" if audio_id else None,
            "is_resumed": existing_record is not None and not existing_record.get("is_finished")
        })

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500
# ===================================================================
# Answer Question
# ===================================================================
@interview_bp.route("/answer", methods=["POST"])
def answer():
    """X·ª≠ l√Ω c√¢u tr·∫£ l·ªùi v√† sinh c√¢u h·ªèi ti·∫øp theo"""

    # ‚úÖ TH√äM: Ki·ªÉm tra auth
    auth_error = require_auth()
    if auth_error:
        return auth_error

    user_id = get_current_user_id()

    try:
        data = request.json
        print(f"üì© D·ªØ li·ªáu FE g·ª≠i ƒë·∫øn v√†o l√∫c {datetime.utcnow()}:", data)

        record_id = data["record_id"]
        answer_text = data["answer"]
        time_spent = data.get("time_spent", 0)

        # ‚úÖ Load record t·ª´ MongoDB
        record_data = db_records.find_one({"_id": ObjectId(record_id)})
        if not record_data:
            return jsonify({
                "error": f"Lu·ª£t ph·ªèng v·∫•n kh√¥ng h·ª£p l·ªá"
            }), 404

        # ‚úÖ TH√äM: Ki·ªÉm tra ownership qua batch_id
        batch_id = record_data.get("batch_id")
        if not verify_batch_ownership(batch_id, user_id):
            return jsonify({
                "success": False,
                "error": "Permission denied"
            }), 403

        # ‚úÖ Deserialize
        record_data.pop('_id', None)
        try:
            record_data['history'] = [
                QuestionAttempt(**{**att, "difficulty": QuestionDifficulty(att["difficulty"])})
                for att in record_data['history']
            ]
            record_data['classified_level'] = Level(record_data['classified_level'])
            record_data['current_difficulty'] = QuestionDifficulty(record_data['current_difficulty'])
            record_data['current_phase'] = InterviewPhase(record_data['current_phase'])
        except Exception as e:
            return jsonify({"error": f"L·ªói d·ªØ li·ªáu b·∫£n ghi: {e}"}), 500

        record_data.pop("reset_count", None)
        record_data.pop("last_reset_at", None)
        record = InterviewRecord(**record_data)

        # ‚úÖ Wake up context
        _, context = wakeup_context(record.batch_id)

        # ‚úÖ Process answer (truy·ªÅn time_spent v√†o)
        updated_record, api_result = interview_processor.process_answer(
            record, context, answer_text, time_spent
        )

        # ‚úÖ Update MongoDB
        record_dict = to_mongo_safe(asdict(updated_record))
        db_records.replace_one({"_id": ObjectId(record_id)}, record_dict)

        # ‚úÖ M·ªöI: N·∫øu finished, tr·∫£ v·ªÅ closing_message ri√™ng
        if api_result.get("finished"):
            # api_result["summary"] ƒë√£ ch·ª©a closing_message t·ª´ processor
            return jsonify({
                "finished": True,
                "closing_message": api_result["summary"].get("closing_message", "C·∫£m ∆°n b·∫°n ƒë√£ tham gia!"),
                "summary": api_result["summary"]  # V·∫´n g·ª≠i summary ƒë·ªÉ FE d√πng sau
            })

        # ‚úÖ Sinh audio cho c√¢u h·ªèi ti·∫øp theo (n·∫øu ch∆∞a finished)
        if "next_question" in api_result:
            audio_id = create_audio_from_text(api_result["next_question"])
            if audio_id:
                api_result["audio_id"] = audio_id
                api_result["audio_url"] = f"{get_base_path()}/audio/{audio_id}"

        return jsonify(to_json_safe(api_result))

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500