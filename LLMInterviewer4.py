# LLMInterviewer4.py - COMPLETE VERSION
# ======================================
# PHI√äN B·∫¢N 3.0: CORE LOGIC PHI TR·∫†NG TH√ÅI (STATELESS)
#
# KI·∫æN TR√öC:
# - File n√†y ch·ªâ ch·ª©a business logic thu·∫ßn t√∫y, kh√¥ng I/O, kh√¥ng load model.
# - L·ªõp `InterviewProcessor` l√† m·ªôt d·ªãch v·ª• phi tr·∫°ng th√°i. N√≥ nh·∫≠n tr·∫°ng th√°i (Record, Context),
#   x·ª≠ l√Ω, v√† tr·∫£ v·ªÅ tr·∫°ng th√°i m·ªõi.
# - To√†n b·ªô vi·ªác qu·∫£n l√Ω tr·∫°ng th√°i (load/save t·ª´ DB), qu·∫£n l√Ω model AI,
#   v√† x·ª≠ l√Ω request/response ƒë∆∞·ª£c chuy·ªÉn cho `app.py`.

import datetime
import hashlib
import re
import json
from dataclasses import dataclass, asdict, field
from enum import Enum
from typing import List, Dict, Optional, Tuple

from langchain_google_genai import GoogleGenerativeAI


# =======================
# 1. Enums & Data Classes
# =======================

class Level(Enum):
    YEU = "yeu"
    TRUNG_BINH = "trung_binh"
    KHA = "kha"
    GIOI = "gioi"
    XUAT_SAC = "xuat_sac"


class QuestionDifficulty(Enum):
    VERY_EASY = "very_easy"
    EASY = "easy"
    MEDIUM = "medium"
    HARD = "hard"
    VERY_HARD = "very_hard"


class InterviewPhase(Enum):
    WARMUP = "warmup"
    TECHNICAL = "technical"
    CLOSING = "closing"


@dataclass
class QuestionAttempt:
    question: str
    answer: str
    score: float
    analysis: str
    difficulty: QuestionDifficulty
    timestamp: str
    question_hash: Optional[str] = None
    time_limit: Optional[int] = None  # ‚úÖ TH√äM FIELD M·ªöI
    time_spent: Optional[int] = None   # ‚úÖ TH√äM: th·ªùi gian th√≠ sinh d√πng (gi√¢y)


@dataclass
class InterviewConfig:
    """C·∫•u h√¨nh cho m·ªôt ƒë·ª£t ph·ªèng v·∫•n."""
    threshold_high: float = 7.0
    threshold_low: float = 4.0
    max_attempts_per_level: int = 2
    max_total_questions: int = 8
    max_upper_level: int = 2
    llm_temperature: float = 0.5
    max_memory_turns: int = 6
    max_warmup_questions: int = 0
    demo_mode: bool = True  # ‚úÖ TH√äM: Flag ƒë·ªÉ demo
    difficulty_map: Dict[Level, List[QuestionDifficulty]] = field(default_factory=lambda: {
        Level.YEU: [QuestionDifficulty.VERY_EASY, QuestionDifficulty.EASY],
        Level.TRUNG_BINH: [QuestionDifficulty.EASY, QuestionDifficulty.EASY],
        Level.KHA: [QuestionDifficulty.MEDIUM, QuestionDifficulty.HARD],
        Level.GIOI: [QuestionDifficulty.MEDIUM, QuestionDifficulty.VERY_HARD],
        Level.XUAT_SAC: [QuestionDifficulty.MEDIUM, QuestionDifficulty.VERY_HARD],
    })


@dataclass
class InterviewContext:
    """
    B·ªëi c·∫£nh chung cho c·∫£ m·ªôt ƒë·ª£t ph·ªèng v·∫•n (Batch).
    Th√¥ng tin n√†y kh√¥ng ƒë·ªïi gi·ªØa c√°c th√≠ sinh.
    """
    topic: str
    outline: Optional[List[str]]
    knowledge_text: str
    outline_summary: str
    config: InterviewConfig


@dataclass
class InterviewRecord:
    """
    B·∫£n ghi tr·∫°ng th√°i c·ªßa m·ªôt lu·ª£t ph·ªèng v·∫•n cho m·ªôt th√≠ sinh.
    ƒê√¢y l√† ƒë·ªëi t∆∞·ª£ng ƒë∆∞·ª£c load v√† save li√™n t·ª•c t·ª´/v√†o DB.
    """
    batch_id: str
    candidate_name: str
    candidate_profile: str
    candidate_context: str
    classified_level: Level
    current_difficulty: QuestionDifficulty
    current_phase: InterviewPhase
    attempts_at_current_level: int
    total_questions_asked: int
    upper_level_reached: int
    warmup_questions_asked: int
    history: List[QuestionAttempt]
    conversation_memory: List[Dict]  # Thay th·∫ø cho ƒë·ªëi t∆∞·ª£ng ConversationMemory
    is_finished: bool
    finish_reason: Optional[str] = None
    final_score: Optional[float] = None
    created_at: str = field(default_factory=lambda: datetime.datetime.now().isoformat())


# =======================
# 2. Utility Functions
# =======================

def classify_level_from_score(score_40: float) -> Level:
    """Ph√¢n lo·∫°i level d·ª±a tr√™n ƒëi·ªÉm 40%"""
    if score_40 < 5.0:
        return Level.YEU
    elif score_40 <= 6.5:
        return Level.TRUNG_BINH
    elif score_40 <= 8.0:
        return Level.KHA
    elif score_40 <= 9.0:
        return Level.GIOI
    else:
        return Level.XUAT_SAC


def get_initial_difficulty(level: Level, config: InterviewConfig) -> QuestionDifficulty:
    """L·∫•y ƒë·ªô kh√≥ ban ƒë·∫ßu cho level"""
    if config.demo_mode:  # ‚úÖ TH√äM
        return QuestionDifficulty.EASY
    return config.difficulty_map[level][0]



def calculate_question_hash(question: str) -> str:
    """Calculate hash c·ªßa c√¢u h·ªèi ƒë·ªÉ detect duplicate"""
    return hashlib.md5(question.encode()).hexdigest()


def _sanitize_question(q: str) -> str:
    """L√†m s·∫°ch chu·ªói c√¢u h·ªèi kh·ªèi k√Ω t·ª± th·ª´a, d·∫•u s·ªë th·ª© t·ª±, backtick..."""
    s = str(q or "").strip()
    s = re.sub(r'^[`\"]+|[`\"]+$', '', s)
    s = re.sub(r'^\s*"\s*', '', s)
    s = re.sub(r'^\s*\(?\d+\)?[\).\s:-]+\s*', '', s)
    s = s.rstrip(",;}]")
    return s.strip()


def _extract_fallback_question(text: str) -> str:
    """C·ªë g·∫Øng tr√≠ch c√¢u h·ªèi n·∫øu JSON l·ªói."""
    # Th·ª≠ b·∫Øt ƒëo·∫°n "question": "..."
    m = re.search(r'"question"\s*:\s*"([\s\S]+?)"\s*}', text)
    if m:
        return m.group(1)
    # N·∫øu kh√¥ng c√≥, l·∫•y d√≤ng d√†i nh·∫•t
    quoted = re.findall(r'"([^"]{20,})"', text, flags=re.S)
    if quoted:
        return quoted[0]
    lines = [ln.strip() for ln in text.splitlines() if len(ln.strip()) > 30]
    return max(lines, key=len) if lines else text


def _clean_and_parse_json_response(raw_text: str, expected_keys: list = None) -> dict:
    """Parse JSON response t·ª´ LLM v·ªõi fallback handling"""
    if not raw_text:
        return {}

    text = raw_text.strip()

    # G·ª° code fence n·∫øu c√≥
    if text.startswith("```"):
        text = re.sub(r"^```[a-zA-Z0-9]*\s*", "", text)
        text = text.rstrip("`").strip("`").strip()

    # L·∫•y ph·∫ßn JSON ch√≠nh
    start, end = text.find("{"), text.rfind("}")
    if start == -1 or end == -1 or end <= start:
        q = _extract_fallback_question(text)
        return {"question": _sanitize_question(q)}

    json_str = text[start:end + 1]

    # Parse JSON an to√†n
    try:
        parsed = json.loads(json_str)
    except json.JSONDecodeError:
        q = _extract_fallback_question(json_str)
        return {"question": _sanitize_question(q)}
    except Exception as e:
        print("‚ö†Ô∏è L·ªói parse JSON:", e)
        q = _extract_fallback_question(json_str)
        return {"question": _sanitize_question(q)}

    # Chu·∫©n h√≥a c√¢u h·ªèi
    if isinstance(parsed, dict) and "question" in parsed:
        q = parsed["question"]
        q = _sanitize_question(q)
        return {"question": q}

    # Fallback cu·ªëi
    q = _extract_fallback_question(text)
    return {"question": _sanitize_question(q)}


def _parse_evaluation_response(raw_text: str) -> dict:
    """Parse JSON k·∫øt qu·∫£ ch·∫•m ƒëi·ªÉm t·ª´ LLM"""
    if not raw_text:
        return {}

    text = raw_text.strip()

    # Lo·∫°i b·ªè code block
    if text.startswith("```"):
        text = re.sub(r"^```[a-zA-Z0-9]*\s*", "", text)
        text = text.rstrip("`").strip("`").strip()

    # T√¨m ƒëo·∫°n JSON trong chu·ªói
    start, end = text.find("{"), text.rfind("}")
    if start != -1 and end != -1:
        json_str = text[start:end + 1]
        try:
            return json.loads(json_str)
        except Exception as e:
            print("‚ö†Ô∏è Parse JSON l·ªói:", e)
            return {}

    return {}


# =======================
# 3. Memory Manager (Helper Class)
# =======================

class ConversationMemory:
    """
    L·ªõp ti·ªán √≠ch t·∫°m th·ªùi ƒë·ªÉ qu·∫£n l√Ω memory trong m·ªôt l·∫ßn x·ª≠ l√Ω.
    N√≥ ƒë∆∞·ª£c t·∫°o ra t·ª´ `conversation_memory` l∆∞u trong `InterviewRecord`.
    """

    def __init__(self, history: List[Dict], max_turns: int):
        self.memory = history
        self.max_turns = max_turns

    def add(self, role: str, content: str):
        self.memory.append({"role": role, "content": content})
        self.memory = self.memory[-self.max_turns:]

    def build_prompt(self) -> str:
        if not self.memory:
            return ""
        return "\n".join([f"{m['role']}: {m['content']}" for m in self.memory])

    def get_history(self) -> List[Dict]:
        """L·∫•y list history ƒë·ªÉ l∆∞u l·∫°i v√†o InterviewRecord."""
        return self.memory


# =======================
# 4. Component Workers
# =======================

class WarmupManager:
    """Component qu·∫£n l√Ω giai ƒëo·∫°n warm-up"""

    def __init__(self, llm: GoogleGenerativeAI):
        self.llm = llm

    def generate_warmup_question(
            self,
            candidate_name: str,
            candidate_context: str,
            topic: str,
            warmup_count: int
    ) -> Dict:  # ‚úÖ ƒê·ªîI: Tr·∫£ v·ªÅ Dict
        """T·∫°o c√¢u h·ªèi warm-up d·ª±a tr√™n context c·ªßa th√≠ sinh"""

        warmup_templates = {
            0: f"""
B·∫°n l√† interviewer AI th√¢n thi·ªán v√† chuy√™n nghi·ªáp.

TH√îNG TIN TH√ç SINH:
{candidate_context}

H√£y ch√†o h·ªèi v√† gi·ªõi thi·ªáu v·ªÅ bu·ªïi ph·ªèng v·∫•n. Bao g·ªìm:
1. Ch√†o th√≠ sinh b·∫±ng t√™n
2. Gi·ªõi thi·ªáu ch·ªß ƒë·ªÅ: "{topic}"
3. ƒê·∫∑t 1 c√¢u h·ªèi warm-up nh·∫π nh√†ng v·ªÅ kinh nghi·ªám/s·ªü th√≠ch li√™n quan ƒë·∫øn {topic}

Y√äU C·∫¶U:
- Th√¢n thi·ªán, t·∫°o kh√¥ng kh√≠ tho·∫£i m√°i
- C√¢u h·ªèi d·ªÖ tr·∫£ l·ªùi, KH√îNG c·∫ßn ki·∫øn th·ª©c s√¢u
- Gi√∫p th√≠ sinh "l√†m n√≥ng m√°y" tr∆∞·ªõc khi v√†o ph·∫ßn chuy√™n m√¥n

OUTPUT: JSON
{{"question": "l·ªùi ch√†o + c√¢u h·ªèi warm-up"}}
""",
            1: f"""
B·∫°n l√† interviewer AI th√¢n thi·ªán, ƒëang ti·∫øp t·ª•c ph·∫ßn warm-up v·ªõi th√≠ sinh {candidate_name}.

TH√îNG TIN TH√ç SINH:
{candidate_context}

C√¢u h·ªèi tr∆∞·ªõc ƒë√£ gi√∫p b·∫°n hi·ªÉu s∆° qua v·ªÅ ·ª©ng vi√™n.
B√¢y gi·ªù, h√£y ƒë·∫∑t th√™m 1 c√¢u h·ªèi warm-up m·ªõi v·ªÅ:
- ƒê·ªông l·ª±c h·ªçc {topic}
- M·ª•c ti√™u ngh·ªÅ nghi·ªáp
- C√°ch ·ª©ng vi√™n c√≥ th·ªÉ √°p d·ª•ng {topic} trong h·ªçc t·∫≠p ho·∫∑c c√¥ng vi·ªác

Y√äU C·∫¶U:
- KH√îNG ch√†o l·∫°i th√≠ sinh (kh√¥ng d√πng "Ch√†o..." ·ªü ƒë·∫ßu)
- C√≥ th·ªÉ b·∫Øt ƒë·∫ßu b·∫±ng c√¢u chuy·ªán ti·∫øp t·ª± nhi√™n:
  "C·∫£m ∆°n chia s·∫ª r·∫•t th√∫ v·ªã c·ªßa b·∫°n, ..."
  "Nghe th·∫≠t hay, ti·∫øp theo t√¥i mu·ªën h·ªèi th√™m..."
- Gi·ªØ gi·ªçng th√¢n thi·ªán, ng·∫Øn g·ªçn, kh√¥ng ƒëi s√¢u k·ªπ thu·∫≠t

OUTPUT: JSON
{{"question": "c√¢u h·ªèi warm-up th·ª© 2, c√≥ l·ªùi chuy·ªÉn m∆∞·ª£t"}}
"""
        }

        prompt = warmup_templates.get(warmup_count, warmup_templates[1])
        result = self.llm.invoke(prompt)
        parsed = _clean_and_parse_json_response(result)

        question = parsed.get("question", f"Xin ch√†o {candidate_name}! B·∫°n ƒë√£ s·∫µn s√†ng cho bu·ªïi ph·ªèng v·∫•n ch∆∞a?")

        # ‚úÖ Tr·∫£ v·ªÅ dict v·ªõi time_limit c·ªë ƒë·ªãnh cho warmup
        return {
            "question": question,
            "difficulty": "warmup",
            "time_limit": 90  # Warmup: 90 gi√¢y (tho·∫£i m√°i h∆°n technical)
        }

    def extract_candidate_context(self, profile: str) -> str:
        """
        Tr√≠ch xu·∫•t th√¥ng tin quan tr·ªçng t·ª´ CV/profile ƒë·ªÉ LLM hi·ªÉu v·ªÅ th√≠ sinh
        Returns: T√≥m t·∫Øt ng·∫Øn g·ªçn v·ªÅ th√≠ sinh (200-300 t·ª´)
        """
        lines = profile.split('\n')
        summary_lines = []
        keywords = ['t√™n', 'l·ªõp', 'ƒëi·ªÉm', 'k·ªπ nƒÉng', 'd·ª± √°n', 'kinh nghi·ªám', 's·ªü th√≠ch']

        for line in lines[:15]:
            if any(kw in line.lower() for kw in keywords):
                summary_lines.append(line)

        context = '\n'.join(summary_lines[:10])
        return context if context else profile[:500]

class QuestionGenerator:
    """Component chuy√™n generate c√¢u h·ªèi"""

    def __init__(self, llm: GoogleGenerativeAI):
        self.llm = llm

    def _estimate_time_limit(self, difficulty: QuestionDifficulty, question: str) -> int:
        """T√≠nh th·ªùi gian g·ª£i √Ω d·ª±a tr√™n ƒë·ªô kh√≥ + c√≥ code hay kh√¥ng."""
        base_times = {
            QuestionDifficulty.VERY_EASY: 90,
            QuestionDifficulty.EASY: 120,
            QuestionDifficulty.MEDIUM: 180,
            QuestionDifficulty.HARD: 240,
            QuestionDifficulty.VERY_HARD: 300,
        }

        time_limit = base_times[difficulty]

        # N·∫øu c√¢u h·ªèi y√™u c·∫ßu ph√¢n t√≠ch code ‚Üí c·ªông th√™m 30 gi√¢y
        if "<pre><code" in question:
            time_limit += 30

        return time_limit

    def generate_with_context(
            self,
            topic: str,
            difficulty: QuestionDifficulty,
            knowledge_text: str,
            memory: ConversationMemory,
            candidate_context: str,
            outline_summary: str = ""
    ) -> Dict:  # ‚úÖ ƒê·ªîI: Tr·∫£ v·ªÅ Dict thay v√¨ str
        """Generate c√¢u h·ªèi c√≥ nh·∫≠n th·ª©c v·ªÅ th√≠ sinh."""

        difficulty_descriptions = {
            QuestionDifficulty.VERY_EASY: (
                "r·∫•t c∆° b·∫£n ‚Äì ki·ªÉm tra s·ª± hi·ªÉu bi·∫øt n·ªÅn t·∫£ng: kh√°i ni·ªám, ƒë·ªãnh nghƒ©a, ho·∫∑c v√≠ d·ª• minh h·ªça ƒë∆°n gi·∫£n. "
                "C√¢u tr·∫£ l·ªùi ng·∫Øn (1‚Äì2 c√¢u), kh√¥ng y√™u c·∫ßu ph√¢n t√≠ch s√¢u. "
                "N·∫øu ch·ªß ƒë·ªÅ li√™n quan ƒë·∫øn l·∫≠p tr√¨nh ho·∫∑c k·ªπ thu·∫≠t, c√≥ th·ªÉ h·ªèi v·ªÅ c√∫ ph√°p, ch·ª©c nƒÉng, ho·∫∑c m·ª•c ƒë√≠ch s·ª≠ d·ª•ng c∆° b·∫£n."
            ),
            QuestionDifficulty.EASY: (
                "c∆° b·∫£n ‚Äì y√™u c·∫ßu ng∆∞·ªùi h·ªçc gi·∫£i th√≠ch √Ω nghƒ©a, so s√°nh, ho·∫∑c n√™u v√≠ d·ª• th·ª±c t·∫ø nh·ªè. "
                "N·∫øu ch·ªß ƒë·ªÅ thu·ªôc lƒ©nh v·ª±c k·ªπ thu·∫≠t, c√≥ th·ªÉ bao g·ªìm m·ªôt ƒëo·∫°n m√£ ng·∫Øn (d∆∞·ªõi 10 d√≤ng) ho·∫∑c t√¨nh hu·ªëng k·ªπ thu·∫≠t ƒë∆°n gi·∫£n ƒë·ªÉ ph√¢n t√≠ch."
            ),
            QuestionDifficulty.MEDIUM: (
                "trung c·∫•p ‚Äì ki·ªÉm tra kh·∫£ nƒÉng v·∫≠n d·ª•ng ki·∫øn th·ª©c v√†o t√¨nh hu·ªëng c·ª• th·ªÉ, ho·∫∑c ph√¢n t√≠ch m·ªëi li√™n h·ªá gi·ªØa c√°c kh√°i ni·ªám. "
                "N·∫øu l√† lƒ©nh v·ª±c phi k·ªπ thu·∫≠t, c√¢u h·ªèi c√≥ th·ªÉ y√™u c·∫ßu tr√¨nh b√†y quan ƒëi·ªÉm, ph√¢n t√≠ch nguy√™n nh√¢n ‚Äì k·∫øt qu·∫£, ho·∫∑c ƒë√°nh gi√° t√¨nh hu·ªëng. "
                "N·∫øu l√† lƒ©nh v·ª±c l·∫≠p tr√¨nh, c√≥ th·ªÉ y√™u c·∫ßu ph√¢n t√≠ch m·ªôt ƒëo·∫°n code (15‚Äì25 d√≤ng) ho·∫∑c m√¥ t·∫£ c√°ch gi·∫£i quy·∫øt m·ªôt v·∫•n ƒë·ªÅ th·ª±c t·∫ø nh·ªè."
            ),
            QuestionDifficulty.HARD: (
                "n√¢ng cao ‚Äì y√™u c·∫ßu t∆∞ duy ph·∫£n bi·ªán, ƒë√°nh gi√° ho·∫∑c t·ªïng h·ª£p th√¥ng tin t·ª´ nhi·ªÅu ngu·ªìn. "
                "Th∆∞·ªùng li√™n quan ƒë·∫øn vi·ªác gi·∫£i th√≠ch quy·∫øt ƒë·ªãnh, ƒë·ªÅ xu·∫•t gi·∫£i ph√°p, ho·∫∑c so s√°nh c√°c ph∆∞∆°ng ph√°p. "
                "N·∫øu ch·ªß ƒë·ªÅ k·ªπ thu·∫≠t, c√≥ th·ªÉ y√™u c·∫ßu thi·∫øt k·∫ø m√¥-ƒëun ho·∫∑c ph√¢n t√≠ch hi·ªáu nƒÉng c·ªßa gi·∫£i ph√°p."
            ),
            QuestionDifficulty.VERY_HARD: (
                "r·∫•t kh√≥ ‚Äì ƒë√≤i h·ªèi nƒÉng l·ª±c t·ªïng h·ª£p, s√°ng t·∫°o ho·∫∑c ·ª©ng d·ª•ng v√†o t√¨nh hu·ªëng ph·ª©c t·∫°p, c√≥ nhi·ªÅu bi·∫øn s·ªë. "
                "C√¢u h·ªèi th∆∞·ªùng m·ªü, kh√¥ng c√≥ c√¢u tr·∫£ l·ªùi duy nh·∫•t, v√† khuy·∫øn kh√≠ch ng∆∞·ªùi h·ªçc l·∫≠p lu·∫≠n logic ho·∫∑c ƒë∆∞a ra quan ƒëi·ªÉm c√≥ d·∫´n ch·ª©ng. "
                "N·∫øu ch·ªß ƒë·ªÅ l√† l·∫≠p tr√¨nh ho·∫∑c k·ªπ thu·∫≠t, c√≥ th·ªÉ m√¥ ph·ªèng m·ªôt h·ªá th·ªëng ho√†n ch·ªânh ho·∫∑c b√†i to√°n thi·∫øt k·∫ø l·ªõn."
            )
        }

        history_text = memory.build_prompt()

        prompt = f"""
        B·∫°n l√† m·ªôt **Interviewer AI chuy√™n nghi·ªáp v√† gi√†u kinh nghi·ªám**, ƒë∆∞·ª£c hu·∫•n luy·ªán ƒë·ªÉ ƒë√°nh gi√° nƒÉng l·ª±c ·ª©ng vi√™n qua ph·ªèng v·∫•n k·ªπ thu·∫≠t.

        =====================
        TH√îNG TIN TH√ç SINH
        =====================
        {candidate_context}

        =====================
        CH·ª¶ ƒê·ªÄ PH·ªéNG V·∫§N
        =====================
        {topic}

        =====================
        L·ªäCH S·ª¨ H·ªòI THO·∫†I (g·∫ßn ƒë√¢y)
        =====================
        {history_text or "Ch∆∞a c√≥ l·ªãch s·ª≠ h·ªôi tho·∫°i"}

        =====================
        T√ÄI LI·ªÜU THAM KH·∫¢O
        =====================
        T√†i li·ªáu c√≥ th·ªÉ r·∫•t d√†i. H√£y ƒë·ªçc ch·ªçn l·ªçc v√† t·∫≠p trung v√†o ph·∫ßn LI√äN QUAN ƒë·∫øn c√¢u h·ªèi m·ªõi.
        {knowledge_text if knowledge_text else "Kh√¥ng c√≥ t√†i li·ªáu"}

        
        
        =====================
        NHI·ªÜM V·ª§
        =====================
        T·∫°o ra **m·ªôt c√¢u h·ªèi ph·ªèng v·∫•n c√° nh√¢n h√≥a** cho th√≠ sinh ·ªü ƒë·ªô kh√≥:
        ‚û°Ô∏è{difficulty.value} {difficulty_descriptions[difficulty]}

        C√¢u h·ªèi c·∫ßn:
        1. Ph√π h·ª£p v·ªõi nƒÉng l·ª±c v√† phong c√°ch tr·∫£ l·ªùi tr∆∞·ªõc ƒë√¢y c·ªßa th√≠ sinh.  
           - N·∫øu th√≠ sinh c√≤n y·∫øu, h√£y d√πng ng√¥n t·ª´ kh√≠ch l·ªá v√† g·ª£i m·ªü.  
           - N·∫øu th√≠ sinh gi·ªèi, ƒë·∫∑t c√¢u h·ªèi th√°ch th·ª©c h∆°n, y√™u c·∫ßu ph√¢n t√≠ch s√¢u.  
        2. C√≥ th·ªÉ bao g·ªìm v√≠ d·ª• code th·ª±c t·∫ø, r√µ r√†ng, d√πng th·∫ª:
           <pre><code class='language-java'>...</code></pre>
        3. C√≥ c·∫•u tr√∫c t·ª± nhi√™n:
           - (a) L·ªùi nh·∫≠n x√©t ho·∫∑c chuy·ªÉn ti·∫øp ng·∫Øn g·ªçn t·ª´ c√¢u tr∆∞·ªõc.
           - (b) C√¢u h·ªèi ch√≠nh (li√™n quan t·ªõi topic).
           - (c) M·ªôt c√¢u g·ª£i m·ªü t√πy ch·ªçn n·∫øu mu·ªën khuy·∫øn kh√≠ch th√≠ sinh m·ªü r·ªông.
        5. Kh√¥ng tr√πng l·∫∑p v·ªõi c√°c c√¢u h·ªèi trong l·ªãch s·ª≠ h·ªôi tho·∫°i.
        6. Gi·ªØ gi·ªçng vƒÉn th√¢n thi·ªán, chuy√™n nghi·ªáp.
        7. L∆∞u √Ω quan tr·ªçng: 
        - V·ªõi nh·ªØng c√¢u h·ªèi d·∫°ng l√Ω thuy·∫øt/ kh√°i ni·ªám , ch·ªâ ƒë∆∞a ra c√¢u h·ªèi khi ch·∫Øc ch·∫Øn t√¨m ƒë∆∞·ª£c c√¢u tr·∫£ l·ªùi trong t√†i li·ªáu.
        - h√£y ch√∫ √Ω tr√°nh h·ªèi nh·ªØng g√¨ m√† t√†i li·ªáu b·ªã ƒë√°nh gi√° l√† thi·∫øu s√≥t d·ª±a v√†o b·∫£n t√≥m t·∫Øt c·ªßa llm.
        8. Kh√¥ng y√™u c·∫ßu vi√™t code, v√¨ l√† bu·ªïi phong v·∫•n h·ªèi ƒë√°p.
        =====================
        T√ìM T·∫ÆT HO·∫∂C OUTLINE
        =====================
        {outline_summary or "Kh√¥ng c√≥"}
        
        =====================
        ƒê·ªäNH D·∫†NG ƒê·∫¶U RA
        =====================
        Tr·∫£ v·ªÅ JSON h·ª£p l·ªá duy nh·∫•t d·∫°ng:

        {{
          "question": "<n·ªôi dung c√¢u h·ªèi>",
          "difficulty": "{difficulty.value}",
          "time_limit": <s·ªë gi√¢y th√≠ sinh n√™n d√†nh ƒë·ªÉ tr·∫£ l·ªùi>
        }}

        ‚ö†Ô∏è Kh√¥ng th√™m m√¥ t·∫£, kh√¥ng tr·∫£ v·ªÅ vƒÉn b·∫£n ngo√†i JSON.
        """
        print(f"ƒêang t·∫°o c√¢u h·ªèi ƒë·ªô kh√≥ {difficulty.value}...")
        result = self.llm.invoke(prompt)
        parsed = _clean_and_parse_json_response(result)

        question = parsed.get("question", "B·∫°n c√≥ th·ªÉ gi·∫£i th√≠ch th√™m ƒë∆∞·ª£c kh√¥ng?")

        # Format code blocks
        question = re.sub(
            r"<pre><code([^>]*)>([\s\S]*?)</code></pre>",
            lambda m: f"<pre><code{m.group(1)}>{m.group(2).replace('<br>', '\n')}</code></pre>",
            question
        )

        # ‚úÖ N·∫øu LLM kh√¥ng tr·∫£ time_limit ‚Üí t·ª± t√≠nh
        if "time_limit" not in parsed or not parsed["time_limit"]:
            time_limit = self._estimate_time_limit(difficulty, question)
        else:
            time_limit = int(parsed["time_limit"])

        # ‚úÖ Tr·∫£ v·ªÅ dict ƒë·∫ßy ƒë·ªß
        return {
            "question": question,
            "difficulty": difficulty.value,
            "time_limit": time_limit
        }

class AnswerEvaluator:
    """Component chuy√™n ch·∫•m ƒëi·ªÉm c√¢u tr·∫£ l·ªùi"""

    def __init__(self, llm: GoogleGenerativeAI):
        self.llm = llm

    def evaluate(
            self,
            question: str,
            answer: str,
            knowledge_text: str
    ) -> Tuple[float, str]:
        """ƒê√°nh gi√° c√¢u tr·∫£ l·ªùi chi ti·∫øt, c√≥ thang ƒëi·ªÉm r√µ r√†ng v√† ph√¢n t√≠ch ng·∫Øn."""

        # N·∫øu knowledge qu√° d√†i, r√∫t g·ªçn nh∆∞ng th√¥ng b√°o cho LLM bi·∫øt
        # truncated_knowledge = knowledge_text
        # if len(knowledge_text) > 10000:
        #     truncated_knowledge = knowledge_text[:8000] + "\n\n...(t√†i li·ªáu b·ªã r√∫t g·ªçn, ch·ªâ hi·ªÉn th·ªã ph·∫ßn ƒë·∫ßu)..."

        prompt = f"""
    B·∫°n l√† **gi√°m kh·∫£o ph·ªèng v·∫•n k·ªπ thu·∫≠t chuy√™n nghi·ªáp**, nhi·ªám v·ª• c·ªßa b·∫°n l√† **ch·∫•m ƒëi·ªÉm c√¢u tr·∫£ l·ªùi c·ªßa ·ª©ng vi√™n** d·ª±a tr√™n **t√†i li·ªáu tham kh·∫£o**.

    ========================
    C√ÇU H·ªéI:
    ========================
    {question}

    ========================
    C√ÇU TR·∫¢ L·ªúI C·ª¶A ·ª®NG VI√äN:
    ========================
    {answer}

    ========================
    T√ÄI LI·ªÜU THAM KH·∫¢O:
    ========================
    {knowledge_text or "Kh√¥ng c√≥ t√†i li·ªáu"}

    ========================
    H∆Ø·ªöNG D·∫™N CH·∫§M ƒêI·ªÇM:
    ========================
    1Ô∏è‚É£ **X√°c ƒë·ªãnh c√°c √Ω ch√≠nh** trong c√¢u tr·∫£ l·ªùi (li·ªát k√™ 2‚Äì5 √Ω quan tr·ªçng).
    2Ô∏è‚É£ **ƒê·ªëi chi·∫øu t·ª´ng √Ω** v·ªõi t√†i li·ªáu tham kh·∫£o:
       - ‚úÖ "Kh·ªõp ch√≠nh x√°c / ƒë√∫ng tr·ªçng t√¢m" ‚Üí 2 ƒëi·ªÉm m·ªói √Ω
       - ‚öôÔ∏è "ƒê√∫ng m·ªôt ph·∫ßn ho·∫∑c m·ªü r·ªông h·ª£p l√Ω ngo√†i t√†i li·ªáu" ‚Üí 1 ƒëi·ªÉm m·ªói √Ω
       - ‚ùå "Sai ho·∫∑c kh√¥ng li√™n quan" ‚Üí 0 ƒëi·ªÉm
    3Ô∏è‚É£ **T·ªïng h·ª£p ƒëi·ªÉm /10**:
       - ƒêi·ªÉm = (ƒëi·ªÉm trung b√¨nh c√°c √Ω) √ó 10 / 2 (gi·ªõi h·∫°n 0‚Äì10)
       - N·∫øu kh√¥ng ƒë·ªß d·ªØ ki·ªán ƒë·ªÉ ƒë√°nh gi√° ‚Üí 5.0 ƒëi·ªÉm m·∫∑c ƒë·ªãnh.
    4Ô∏è‚É£ ƒê∆∞a ra **nh·∫≠n x√©t ng·∫Øn g·ªçn (1‚Äì3 c√¢u)**:
       - N√™u ƒëi·ªÉm m·∫°nh v√† ƒëi·ªÉm c·∫ßn c·∫£i thi·ªán.
       - Vi·∫øt gi·ªçng kh√°ch quan, mang t√≠nh kh√≠ch l·ªá.

    ========================
    ƒê·ªäNH D·∫†NG K·∫æT QU·∫¢ TR·∫¢ V·ªÄ:
    ========================
    Tr·∫£ v·ªÅ JSON h·ª£p l·ªá duy nh·∫•t nh∆∞ sau:

    {{
      "score": <float 0-10>,
      "analysis": "<ph√¢n t√≠ch ng·∫Øn g·ªçn, 1‚Äì3 c√¢u>"
    }}

    ‚ö†Ô∏è Kh√¥ng tr·∫£ v·ªÅ text kh√°c ngo√†i JSON.
    """

        try:
            result = self.llm.invoke(prompt)
            parsed = _parse_evaluation_response(result)

            score = float(parsed.get("score", 5.0))
            analysis = parsed.get("analysis", "Kh√¥ng c√≥ nh·∫≠n x√©t")

            # Chu·∫©n h√≥a ƒëi·ªÉm
            score = max(0.0, min(10.0, score))

            return score, analysis

        except Exception as e:
            print(f"‚ö†Ô∏è L·ªói khi ch·∫•m ƒëi·ªÉm: {e}")
            return 5.0, "L·ªói khi ch·∫•m ƒëi·ªÉm, m·∫∑c ƒë·ªãnh 5/10"


class DifficultyAdapter:
    """Component ƒëi·ªÅu ch·ªânh ƒë·ªô kh√≥"""

    def decide_next_action(self, score: float, config: InterviewConfig) -> str:
        """Quy·∫øt ƒë·ªãnh action ti·∫øp theo"""
        if score >= config.threshold_high:
            return "harder"
        if score >= config.threshold_low:
            return "same"
        return "easier"

    def get_next_difficulty(
            self,
            current: QuestionDifficulty,
            action: str
    ) -> QuestionDifficulty:
        """T√≠nh ƒë·ªô kh√≥ ti·∫øp theo"""
        difficulties = list(QuestionDifficulty)
        current_idx = difficulties.index(current)

        if action == "harder" and current_idx < len(difficulties) - 1:
            return difficulties[current_idx + 1]
        if action == "easier" and current_idx > 0:
            return difficulties[current_idx - 1]
        return current


# =======================
# 5. B·ªò X·ª¨ L√ù LOGIC PH·ªéNG V·∫§N (STATELESS PROCESSOR)
# =======================

class InterviewProcessor:
    """
    B·ªô x·ª≠ l√Ω logic ph·ªèng v·∫•n phi tr·∫°ng th√°i.
    N√≥ nh·∫≠n tr·∫°ng th√°i, x·ª≠ l√Ω, v√† tr·∫£ v·ªÅ tr·∫°ng th√°i m·ªõi.
    Kh√¥ng t·ª± m√¨nh load model hay k·∫øt n·ªëi DB.
    """

    def __init__(self, llm: GoogleGenerativeAI):
        """Kh·ªüi t·∫°o processor v·ªõi c√°c dependency c·∫ßn thi·∫øt (LLM)."""
        self.llm = llm

        # Kh·ªüi t·∫°o c√°c component worker
        self.warmup_manager = WarmupManager(self.llm)
        self.question_generator = QuestionGenerator(self.llm)
        self.answer_evaluator = AnswerEvaluator(self.llm)
        self.difficulty_adapter = DifficultyAdapter()
        self.closing_generator = ClosingGenerator(self.llm)  # ‚úÖ TH√äM

    def start_new_record(
            self,
            batch_id: str,
            candidate_name: str,
            candidate_profile: str,
            classified_level: Level,
            context: InterviewContext
    ) -> Tuple[InterviewRecord, Dict]:
        """
        Kh·ªüi t·∫°o m·ªôt b·∫£n ghi ph·ªèng v·∫•n m·ªõi cho th√≠ sinh.
        """
        config = context.config
        initial_difficulty = get_initial_difficulty(classified_level, config)
        candidate_context = self.warmup_manager.extract_candidate_context(candidate_profile)

        # ‚úÖ LOGIC M·ªöI: Ki·ªÉm tra xem c√≥ c·∫ßn Warmup kh√¥ng
        # N·∫øu max_warmup_questions > 0 th√¨ v√†o WARMUP, ng∆∞·ª£c l·∫°i v√†o TECHNICAL lu√¥n
        start_phase = InterviewPhase.WARMUP if config.max_warmup_questions > 0 else InterviewPhase.TECHNICAL

        # T·∫°o b·∫£n ghi tr·∫°ng th√°i ban ƒë·∫ßu
        record = InterviewRecord(
            batch_id=batch_id,
            candidate_name=candidate_name,
            candidate_profile=candidate_profile,
            candidate_context=candidate_context,
            classified_level=classified_level,
            current_difficulty=initial_difficulty,
            current_phase=start_phase,  # ‚úÖ D√πng bi·∫øn ƒë√£ check
            attempts_at_current_level=0,
            total_questions_asked=0,
            upper_level_reached=0,
            warmup_questions_asked=0,
            history=[],
            conversation_memory=[],
            is_finished=False
        )

        first_q_data = {}

        # ---------------------------------------------------------
        # TR∆Ø·ªúNG H·ª¢P 1: C√ì WARMUP
        # ---------------------------------------------------------
        if start_phase == InterviewPhase.WARMUP:
            warmup_data = self.warmup_manager.generate_warmup_question(
                candidate_name=candidate_name.split(',')[0],
                candidate_context=candidate_context,
                topic=context.topic,
                warmup_count=0
            )

            first_q_data = warmup_data

            # Th√™m v√†o history
            record.history.append(QuestionAttempt(
                question=warmup_data["question"],
                answer="",
                score=0.0,
                analysis="(warmup - kh√¥ng ch·∫•m ƒëi·ªÉm)",
                difficulty=QuestionDifficulty.VERY_EASY,
                timestamp=datetime.datetime.now().isoformat(),
                question_hash=calculate_question_hash(warmup_data["question"]),
                time_limit=warmup_data["time_limit"]
            ))

        # ---------------------------------------------------------
        # TR∆Ø·ªúNG H·ª¢P 2: KH√îNG WARMUP -> V√ÄO TECHNICAL LU√îN
        # ---------------------------------------------------------
        else:
            # T·∫°o memory tr·ªëng ban ƒë·∫ßu
            memory = ConversationMemory([], config.max_memory_turns)

            # Generate c√¢u h·ªèi k·ªπ thu·∫≠t ƒë·∫ßu ti√™n
            tech_data = self.question_generator.generate_with_context(
                context.topic,
                record.current_difficulty,
                context.knowledge_text,
                memory,
                record.candidate_context,
                context.outline_summary
            )

            first_q_data = {
                "question": tech_data["question"],
                "difficulty": tech_data["difficulty"],
                "time_limit": tech_data["time_limit"],
                "phase": "technical"
            }

            # Th√™m v√†o history
            record.history.append(QuestionAttempt(
                question=tech_data["question"],
                answer="",
                score=0.0,
                analysis="(pending)",
                difficulty=record.current_difficulty,
                timestamp=datetime.datetime.now().isoformat(),
                question_hash=calculate_question_hash(tech_data["question"]),
                time_limit=tech_data["time_limit"]
            ))

        return record, first_q_data

    def process_answer(
            self,
            record: InterviewRecord,
            context: InterviewContext,
            answer: str,
            time_spent: int = 0  # ‚úÖ TH√äM: th·ªùi gian th√≠ sinh ƒë√£ d√πng (gi√¢y)
    ) -> Tuple[InterviewRecord, Dict]:
        """
        X·ª≠ l√Ω c√¢u tr·∫£ l·ªùi c·ªßa th√≠ sinh, c·∫≠p nh·∫≠t b·∫£n ghi v√† t·∫°o c√¢u h·ªèi ti·∫øp theo.

        Args:
            record: B·∫£n ghi ph·ªèng v·∫•n hi·ªán t·∫°i
            context: Context c·ªßa batch
            answer: C√¢u tr·∫£ l·ªùi c·ªßa th√≠ sinh
            time_spent: Th·ªùi gian th√≠ sinh ƒë√£ d√πng (gi√¢y)

        Returns:
            - InterviewRecord: B·∫£n ghi tr·∫°ng th√°i ƒë√£ ƒë∆∞·ª£c c·∫≠p nh·∫≠t.
            - Dict: K·∫øt qu·∫£ ƒë·ªÉ tr·∫£ v·ªÅ cho API (ch·ª©a c√¢u h·ªèi ti·∫øp theo, ƒëi·ªÉm, time_limit, etc.).
        """
        if record.is_finished:
            summary = self._generate_summary(record, context)
            return record, {"finished": True, "summary": summary}

        # ‚úÖ C·∫≠p nh·∫≠t time_spent v√†o attempt cu·ªëi c√πng
        if record.history:
            record.history[-1].time_spent = time_spent

        if record.current_phase == InterviewPhase.WARMUP:
            return self._handle_warmup_answer(record, context, answer)
        elif record.current_phase == InterviewPhase.TECHNICAL:
            return self._handle_technical_answer(record, context, answer)
        else:  # Closing
            summary = self._generate_summary(record, context)
            record.is_finished = True
            return record, {"finished": True, "summary": summary}

    def _handle_warmup_answer(
            self,
            record: InterviewRecord,
            context: InterviewContext,
            answer: str
    ) -> Tuple[InterviewRecord, Dict]:
        """X·ª≠ l√Ω c√¢u tr·∫£ l·ªùi trong giai ƒëo·∫°n warm-up."""
        config = context.config

        # C·∫≠p nh·∫≠t c√¢u tr·∫£ l·ªùi v√†o attempt cu·ªëi c√πng
        last_attempt = record.history[-1]
        last_attempt.answer = answer
        last_attempt.analysis = "‚úÖ C·∫£m ∆°n b·∫°n ƒë√£ chia s·∫ª!"

        # C·∫≠p nh·∫≠t memory
        memory = ConversationMemory(record.conversation_memory, config.max_memory_turns)
        memory.add("student", answer)
        memory.add("interviewer", "C·∫£m ∆°n b·∫°n!")
        record.conversation_memory = memory.get_history()

        record.warmup_questions_asked += 1

        if record.warmup_questions_asked >= config.max_warmup_questions:
            # ‚úÖ Chuy·ªÉn sang giai ƒëo·∫°n technical
            record.current_phase = InterviewPhase.TECHNICAL

            # ‚úÖ Nh·∫≠n Dict thay v√¨ str
            next_q_data = self.question_generator.generate_with_context(
                context.topic, record.current_difficulty, context.knowledge_text,
                memory, record.candidate_context, context.outline_summary
            )

            api_result = {
                "finished": False,
                "score": 0,
                "analysis": "‚úÖ Ph·∫ßn l√†m quen ho√†n t·∫•t! B√¢y gi·ªù ch√∫ng ta b·∫Øt ƒë·∫ßu ph·∫ßn chuy√™n m√¥n nh√©.",
                "next_question": next_q_data["question"],  # ‚úÖ
                "difficulty": next_q_data["difficulty"],  # ‚úÖ
                "time_limit": next_q_data["time_limit"],  # ‚úÖ TH√äM
                "phase": "technical"
            }

            # ‚úÖ Th√™m c√¢u h·ªèi m·ªõi v√†o history v·ªõi time_limit
            record.history.append(QuestionAttempt(
                question=next_q_data["question"],
                answer="",
                score=0.0,
                analysis="(pending)",
                difficulty=record.current_difficulty,
                timestamp=datetime.datetime.now().isoformat(),
                question_hash=calculate_question_hash(next_q_data["question"]),
                time_limit=next_q_data["time_limit"]  # ‚úÖ
            ))
        else:
            # ‚úÖ H·ªèi c√¢u warm-up ti·∫øp theo (nh·∫≠n Dict)
            warmup_data = self.warmup_manager.generate_warmup_question(
                record.candidate_name.split(',')[0],
                record.candidate_context,
                context.topic,
                record.warmup_questions_asked
            )

            api_result = {
                "finished": False,
                "score": 0,
                "analysis": "‚úÖ Tuy·ªát v·ªùi!",
                "next_question": warmup_data["question"],  # ‚úÖ
                "difficulty": warmup_data["difficulty"],  # ‚úÖ
                "time_limit": warmup_data["time_limit"],  # ‚úÖ TH√äM
                "phase": "warmup"
            }

            # ‚úÖ Th√™m c√¢u h·ªèi m·ªõi v√†o history v·ªõi time_limit
            record.history.append(QuestionAttempt(
                question=warmup_data["question"],
                answer="",
                score=0.0,
                analysis="(pending)",
                difficulty=record.current_difficulty,
                timestamp=datetime.datetime.now().isoformat(),
                question_hash=calculate_question_hash(warmup_data["question"]),
                time_limit=warmup_data["time_limit"]  # ‚úÖ
            ))

        return record, api_result

    def _handle_technical_answer(
            self,
            record: InterviewRecord,
            context: InterviewContext,
            answer: str
    ) -> Tuple[InterviewRecord, Dict]:
        """X·ª≠ l√Ω c√¢u tr·∫£ l·ªùi trong giai ƒëo·∫°n technical."""
        config = context.config
        last_attempt = record.history[-1]
        memory = ConversationMemory(record.conversation_memory, config.max_memory_turns)

        # Ch·∫•m ƒëi·ªÉm
        score, analysis = self.answer_evaluator.evaluate(
            last_attempt.question,
            answer,
            context.knowledge_text
        )
        print("Th·ªùi gian ƒë√°nh gi√° xong:", datetime.datetime.now().isoformat())

        # C·∫≠p nh·∫≠t attempt v√† memory
        last_attempt.answer = answer
        last_attempt.score = score
        last_attempt.analysis = analysis
        memory.add("student", answer)
        memory.add("interviewer", f"üìä ƒêi·ªÉm: {score}/10 - {analysis}")
        record.conversation_memory = memory.get_history()

        # C·∫≠p nh·∫≠t tr·∫°ng th√°i t·ªïng th·ªÉ c·ªßa record
        self._update_record_state(record, score, config)

        # Ki·ªÉm tra k·∫øt th√∫c
        if record.is_finished:
            summary = self._generate_summary(record, context)
            return record, {"finished": True, "summary": summary}

        # ‚úÖ T·∫°o c√¢u h·ªèi ti·∫øp theo (nh·∫≠n Dict)
        next_q_data = self.question_generator.generate_with_context(
            context.topic,
            record.current_difficulty,
            context.knowledge_text,
            memory,
            record.candidate_context,
            context.outline_summary
        )
        print(f"Th·ªùi gian t·∫°o c√¢u h·ªèi k·ªπ thu·∫≠t ti·∫øp theo xong:", datetime.datetime.now().isoformat())

        # ‚úÖ Th√™m c√¢u h·ªèi m·ªõi v√†o history v·ªõi time_limit
        record.history.append(QuestionAttempt(
            question=next_q_data["question"],
            answer="",
            score=0.0,
            analysis="(pending)",
            difficulty=record.current_difficulty,
            timestamp=datetime.datetime.now().isoformat(),
            question_hash=calculate_question_hash(next_q_data["question"]),
            time_limit=next_q_data["time_limit"]  # ‚úÖ
        ))

        api_result = {
            "finished": False,
            "score": score,
            "analysis": analysis,
            "next_question": next_q_data["question"],  # ‚úÖ
            "difficulty": next_q_data["difficulty"],  # ‚úÖ
            "time_limit": next_q_data["time_limit"],  # ‚úÖ TH√äM
            "phase": "technical"
        }

        return record, api_result

    def _update_record_state(
            self,
            record: InterviewRecord,
            score: float,
            config: InterviewConfig
    ):
        """Update tr·∫°ng th√°i c·ªßa record d·ª±a tr√™n ƒëi·ªÉm s·ªë c√¢u tr·∫£ l·ªùi."""
        record.total_questions_asked += 1
        action = self.difficulty_adapter.decide_next_action(score, config)

        if action == "harder":
            record.upper_level_reached += 1
            if record.upper_level_reached <= config.max_upper_level:
                record.current_difficulty = self.difficulty_adapter.get_next_difficulty(
                    record.current_difficulty, "harder"
                )
                record.attempts_at_current_level = 0
            else:
                record.is_finished = True
                record.finish_reason = "max_upper_level"  # ‚úÖ TH√äM

        elif action == "same":
            record.attempts_at_current_level += 1

        else:  # easier
            record.current_difficulty = self.difficulty_adapter.get_next_difficulty(
                record.current_difficulty, "easier"
            )
            record.attempts_at_current_level += 1
            record.upper_level_reached = max(0, record.upper_level_reached - 1)

        # ‚úÖ C·∫¨P NH·∫¨T: Ghi finish_reason chi ti·∫øt
        if record.attempts_at_current_level >= config.max_attempts_per_level:
            record.is_finished = True
            record.finish_reason = "max_attempts"  # ‚úÖ TH√äM

        if record.total_questions_asked >= config.max_total_questions:
            record.is_finished = True
            if not record.finish_reason:  # ∆Øu ti√™n l√Ω do ƒë·∫ßu ti√™n
                record.finish_reason = "max_questions"  # ‚úÖ TH√äM

        # T√≠nh ƒëi·ªÉm cu·ªëi c√πng n·∫øu ƒë√£ k·∫øt th√∫c
        if record.is_finished:
            technical_scores = [
                attempt.score
                for attempt in record.history
                if attempt.score > 0 and "warmup" not in attempt.analysis.lower()
            ]
            record.final_score = sum(technical_scores) / len(technical_scores) if technical_scores else 0.0

    def _generate_summary(
            self,
            record: InterviewRecord,
            context: InterviewContext
    ) -> Dict:
        """T·∫°o b·∫£n t√≥m t·∫Øt cu·ªëi c√πng c·ªßa bu·ªïi ph·ªèng v·∫•n."""

        # Convert QuestionAttempt objects to dicts
        history_dicts = []
        for i, attempt in enumerate(record.history, 1):
            attempt_dict = asdict(attempt)

            # Convert Enum to string
            if isinstance(attempt_dict['difficulty'], QuestionDifficulty):
                attempt_dict['difficulty'] = attempt_dict['difficulty'].value
            elif hasattr(attempt_dict['difficulty'], 'value'):
                attempt_dict['difficulty'] = attempt_dict['difficulty'].value

            # Add question number
            attempt_dict['question_number'] = i
            history_dicts.append(attempt_dict)

        # ‚úÖ TH√äM: Generate closing message
        closing_message = self.closing_generator.generate_closing_message(
            candidate_name=record.candidate_name.split(',')[0],  # L·∫•y t√™n ng·∫Øn
            finish_reason=record.finish_reason or "completed",
            final_score=record.final_score or 0.0,
            total_questions=len(record.history),
            topic=context.topic
        )

        return {
            "candidate_info": {
                "name": record.candidate_name,
                "profile": record.candidate_profile,
                "classified_level": record.classified_level.value
            },
            "interview_stats": {
                "timestamp": datetime.datetime.now().isoformat(),
                "total_questions": len(record.history),
                "final_score": record.final_score,
                "finish_reason": record.finish_reason,  # ‚úÖ TH√äM
                "topic": context.topic,
                "outline": context.outline
            },
            "closing_message": closing_message,  # ‚úÖ TH√äM
            "question_history": history_dicts
        }


class ClosingGenerator:
    """Component t·∫°o l·ªùi k·∫øt th√∫c t·ª± nhi√™n"""

    def __init__(self, llm: GoogleGenerativeAI):
        self.llm = llm

    def generate_closing_message(
            self,
            candidate_name: str,
            finish_reason: str,
            final_score: float,
            total_questions: int,
            topic: str
    ) -> str:
        """
        T·∫°o l·ªùi k·∫øt th√∫c t·ª± nhi√™n d·ª±a tr√™n l√Ω do k·∫øt th√∫c ph·ªèng v·∫•n.

        Args:
            candidate_name: T√™n th√≠ sinh
            finish_reason: L√Ω do k·∫øt th√∫c ("max_attempts" | "max_questions" | "max_upper_level")
            final_score: ƒêi·ªÉm trung b√¨nh cu·ªëi c√πng
            total_questions: T·ªïng s·ªë c√¢u h·ªèi ƒë√£ h·ªèi
            topic: Ch·ªß ƒë·ªÅ ph·ªèng v·∫•n
        """

        reason_context = {
            "max_attempts": f"B·∫°n ƒë√£ ho√†n th√†nh {total_questions} c√¢u h·ªèi ·ªü m·ª©c ƒë·ªô hi·ªán t·∫°i.",
            "max_questions": f"Ch√∫ng ta ƒë√£ tr·∫£i qua {total_questions} c√¢u h·ªèi v·ªÅ {topic}.",
            "max_upper_level": f"B·∫°n ƒë√£ v∆∞·ª£t qua nhi·ªÅu m·ª©c ƒë·ªô th·ª≠ th√°ch kh√°c nhau trong {total_questions} c√¢u h·ªèi."
        }

        context_text = reason_context.get(finish_reason, f"Ch√∫ng ta ƒë√£ ho√†n th√†nh {total_questions} c√¢u h·ªèi.")

        prompt = f"""
B·∫°n l√† interviewer AI th√¢n thi·ªán v√† chuy√™n nghi·ªáp, ƒëang k·∫øt th√∫c bu·ªïi ph·ªèng v·∫•n v·ªõi {candidate_name}.

B·ªêI C·∫¢NH:
- Ch·ªß ƒë·ªÅ ph·ªèng v·∫•n: {topic}
- {context_text}
- ƒêi·ªÉm trung b√¨nh: {final_score:.1f}/10

NHI·ªÜM V·ª§:
T·∫°o m·ªôt l·ªùi k·∫øt th√∫c T·ª∞ NHI√äN, TH√ÇN THI·ªÜN v√† CHUY√äN NGHI·ªÜP (2-4 c√¢u) bao g·ªìm:
1. C·∫£m ∆°n th√≠ sinh ƒë√£ tham gia
2. Nh·∫≠n x√©t t√≠ch c·ª±c v·ªÅ qu√° tr√¨nh (d·ª±a tr√™n ƒëi·ªÉm s·ªë)
3. ƒê·ªông vi√™n/kh√≠ch l·ªá
4. Th√¥ng b√°o k·∫øt th√∫c m∆∞·ª£t m√†

Y√äU C·∫¶U:
- Gi·ªçng vƒÉn ·∫•m √°p, kh√≠ch l·ªá
- KH√îNG ƒë·ªÅ c·∫≠p chi ti·∫øt k·ªπ thu·∫≠t
- KH√îNG n√≥i "JSON" hay b·∫•t k·ª≥ thu·∫≠t ng·ªØ l·∫≠p tr√¨nh n√†o
- Gi·ªØ ng·∫Øn g·ªçn (50-80 t·ª´)

OUTPUT: Ch·ªâ tr·∫£ v·ªÅ vƒÉn b·∫£n l·ªùi k·∫øt, KH√îNG c√≥ JSON, KH√îNG c√≥ markdown.
"""

        try:
            result = self.llm.invoke(prompt)
            closing_text = result.strip()

            # Lo·∫°i b·ªè c√°c artifact kh√¥ng mong mu·ªën
            closing_text = re.sub(r'^```.*\n|```$', '', closing_text, flags=re.MULTILINE)
            closing_text = re.sub(r'^\{.*\}$', '', closing_text, flags=re.DOTALL)

            return closing_text if closing_text else self._get_fallback_closing(candidate_name, final_score)

        except Exception as e:
            print(f"‚ö†Ô∏è L·ªói khi t·∫°o l·ªùi k·∫øt: {e}")
            return self._get_fallback_closing(candidate_name, final_score)

    def _get_fallback_closing(self, candidate_name: str, final_score: float) -> str:
        """L·ªùi k·∫øt m·∫∑c ƒë·ªãnh n·∫øu LLM fail"""
        if final_score >= 7.0:
            return f"C·∫£m ∆°n {candidate_name} ƒë√£ tham gia bu·ªïi ph·ªèng v·∫•n! B·∫°n ƒë√£ th·ªÉ hi·ªán r·∫•t t·ªët trong su·ªët qu√° tr√¨nh. Ch√∫c b·∫°n th√†nh c√¥ng!"
        elif final_score >= 5.0:
            return f"C·∫£m ∆°n {candidate_name}! B·∫°n ƒë√£ n·ªó l·ª±c r·∫•t t·ªët. H√£y ti·∫øp t·ª•c h·ªçc h·ªèi v√† ph√°t tri·ªÉn th√™m nh√©. Ch√∫c b·∫°n may m·∫Øn!"
        else:
            return f"C·∫£m ∆°n {candidate_name} ƒë√£ tham gia! ƒê√¢y l√† m·ªôt tr·∫£i nghi·ªám qu√Ω gi√°. H√£y ti·∫øp t·ª•c c·ªë g·∫Øng v√† r√®n luy·ªán th√™m nh√©!"