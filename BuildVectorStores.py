import os
import time
import tempfile
from dotenv import load_dotenv
import nltk
from pymongo import MongoClient
from datetime import datetime
from typing import List, Dict, Tuple, Optional
import hashlib

from config import Config
from extensions import embedding_manager

# ======================
# 1. Chu·∫©n b·ªã NLTK
# ======================
nltk.download("punkt", quiet=True)
try:
    nltk.download("punkt_tab", quiet=True)
except:
    pass

from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import NLTKTextSplitter, RecursiveCharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.schema import Document

# ======================
# Danh s√°ch model h·ª£p l·ªá v·ªõi m√¥ t·∫£
# ======================
VALID_MODELS = {
    "intfloat/multilingual-e5-large-instruct": {
        "name": "Multilingual E5 Large Instruct",
        "languages": ["vi", "en", "multi"],
        "dimension": 1024,
        "description": "Model ƒëa ng√¥n ng·ªØ m·∫°nh m·∫Ω, t·ªët cho ti·∫øng Vi·ªát"
    },
    "hiieu/halong_embedding": {
        "name": "hiieu/halong_embedding",
        "languages": ["vi"],
        "dimension": 768,
        "description": "Model t·ªëi ∆∞u cho ti·∫øng Vi·ªát"
    },
    "AITeamVN/Vietnamese_Embedding": {
        "name": "AITeamVN/Vietnamese_Embedding",
        "languages": ["vi"],
        "dimension": 1024,
        "description": "Model chuy√™n bi·ªát cho ti·∫øng Vi·ªát"
    }
}

# ======================
# Configuration
# ======================
# Th∆∞ m·ª•c l∆∞u vectorstores (relative to this file)
PROJECT_ROOT = os.path.dirname(os.path.abspath(__file__))
DEFAULT_VECTORSTORES_DIR = os.path.join(PROJECT_ROOT, "vectorstores")


# ======================
# Text Splitter Strategy
# ======================
class TextSplitterStrategy:
    """Strategy pattern cho text splitting"""

    @staticmethod
    def get_splitter(strategy: str, chunk_size: int, chunk_overlap: int):
        if strategy == "nltk":
            return NLTKTextSplitter(
                chunk_size=chunk_size,
                chunk_overlap=chunk_overlap,
                separator="\n\n",
            )
        elif strategy == "recursive":
            return RecursiveCharacterTextSplitter(
                chunk_size=chunk_size,
                chunk_overlap=chunk_overlap,
                separators=["\n\n", "\n", ". ", " ", ""],
            )
        else:
            raise ValueError(f"Unknown strategy: {strategy}")


# ======================
# Utility Functions
# ======================
def calculate_file_hash(file_path: str) -> str:
    """T√≠nh hash c·ªßa file ƒë·ªÉ detect duplicate"""
    hash_md5 = hashlib.md5()
    with open(file_path, "rb") as f:
        for chunk in iter(lambda: f.read(4096), b""):
            hash_md5.update(chunk)
    return hash_md5.hexdigest()


def clean_text(text: str) -> str:
    """L√†m s·∫°ch text tr∆∞·ªõc khi embedding"""
    # Lo·∫°i b·ªè whitespace th·ª´a
    text = " ".join(text.split())
    # Lo·∫°i b·ªè c√°c k√Ω t·ª± ƒë·∫∑c bi·ªát kh√¥ng c·∫ßn thi·∫øt
    text = text.replace("\x00", "")
    return text.strip()


def validate_pdf(pdf_path: str) -> Tuple[bool, Optional[str]]:
    """Validate PDF file"""
    if not os.path.exists(pdf_path):
        return False, "File kh√¥ng t·ªìn t·∫°i"

    if not pdf_path.lower().endswith('.pdf'):
        return False, "File kh√¥ng ph·∫£i ƒë·ªãnh d·∫°ng PDF"

    file_size = os.path.getsize(pdf_path)
    max_size = 50 * 1024 * 1024  # 50MB
    if file_size > max_size:
        return False, f"File qu√° l·ªõn (>{max_size / 1024 / 1024}MB)"

    if file_size == 0:
        return False, "File r·ªóng"

    return True, None


def check_duplicate_vectorstore(mongo_uri, file_hash, model_name, chunk_size, chunk_overlap, user_id=None):
    client = MongoClient(mongo_uri)
    db = client["interviewer_ai"]
    collection = db["vectorstores"]

    query = {
        "file_hash": file_hash,
        "model_name": model_name,
        "chunk_size": chunk_size,
        "chunk_overlap": chunk_overlap,
        "status": "active"  # ‚úÖ ch·ªâ check b·∫£n ƒëang ho·∫°t ƒë·ªông
    }

    if user_id:
        query["$or"] = [
            {"user_id": user_id},
            {"custom.user_id": user_id}
        ]

    existing = collection.find_one(query)
    return existing




# ======================
# Main Function - Improved
# ======================
def build_vectorstore(
        pdf_path: str,
        chunk_size: int = 1600,
        chunk_overlap: int = 400,
        model_name: str = "intfloat/multilingual-e5-large-instruct",
        mongo_uri: str = "mongodb://localhost:27017/",
        splitter_strategy: str = "nltk",
        skip_duplicate: bool = True,
        custom_metadata: Optional[Dict] = None,
        progress_callback: Optional[callable] = None,
        output_dir: Optional[str] = None  # NEW: Cho ph√©p custom output dir
        ,user_id: Optional[str] = None  # ‚úÖ TH√äM
) -> Tuple[str, Dict]:
    """
    Build vectorstore v·ªõi nhi·ªÅu c·∫£i ti·∫øn

    Args:
        pdf_path: ƒê∆∞·ªùng d·∫´n file PDF
        chunk_size: K√≠ch th∆∞·ªõc m·ªói chunk
        chunk_overlap: Overlap gi·ªØa c√°c chunk
        model_name: T√™n model embedding
        mongo_uri: URI MongoDB
        splitter_strategy: Chi·∫øn l∆∞·ª£c chia vƒÉn b·∫£n ('nltk' ho·∫∑c 'recursive')
        skip_duplicate: B·ªè qua n·∫øu ƒë√£ t·ªìn t·∫°i vectorstore gi·ªëng h·ªát
        custom_metadata: Metadata t√πy ch·ªânh
        progress_callback: Callback function ƒë·ªÉ b√°o c√°o ti·∫øn ƒë·ªô

    Returns:
        Tuple[save_path, metadata]
    """

    def report_progress(stage: str, progress: int):
        if progress_callback:
            progress_callback(stage, progress)

    # Validate model
    if model_name not in VALID_MODELS:
        raise ValueError(f"Model {model_name} kh√¥ng h·ª£p l·ªá. Ch·ªçn t·ª´: {list(VALID_MODELS.keys())}")

    # Validate PDF
    is_valid, error_msg = validate_pdf(pdf_path)
    if not is_valid:
        raise ValueError(f"PDF kh√¥ng h·ª£p l·ªá: {error_msg}")

    report_progress("validation", 10)

    # Calculate file hash
    file_hash = calculate_file_hash(pdf_path)

    if skip_duplicate:
        existing = check_duplicate_vectorstore(
            mongo_uri,
            file_hash,
            model_name,
            chunk_size,
            chunk_overlap,
            user_id=user_id or (custom_metadata or {}).get("user_id")  # ‚úÖ TH√äM
        )
        if existing:
            print(f"‚ö†Ô∏è Vectorstore ƒë√£ t·ªìn t·∫°i (user_id={user_id}): {existing['vectorstore_name']}")
            return existing['vectorstore_path'], existing

    report_progress("loading", 20)

    # Load PDF
    try:
        loader = PyPDFLoader(pdf_path)
        pages = loader.load()
        print(f"üìÑ ƒê√£ load {len(pages)} trang t·ª´ PDF")
    except Exception as e:
        raise ValueError(f"L·ªói khi load PDF: {str(e)}")

    if not pages:
        raise ValueError("PDF kh√¥ng c√≥ n·ªôi dung")

    # Clean v√† merge text
    full_text = "\n".join([clean_text(p.page_content) for p in pages])
    full_doc = [Document(page_content=full_text, metadata={"source": pdf_path})]

    report_progress("splitting", 40)

    # Split text
    text_splitter = TextSplitterStrategy.get_splitter(
        splitter_strategy, chunk_size, chunk_overlap
    )

    splitted_docs = []
    for doc in full_doc:
        chunks = text_splitter.split_text(doc.page_content)
        for i, chunk in enumerate(chunks):
            splitted_docs.append({
                "page_content": clean_text(chunk),
                "metadata": {
                    **doc.metadata,
                    "chunk_index": i,
                    "chunk_size": len(chunk),
                    "splitter": splitter_strategy,

                }
            })

    print(f"‚úÇÔ∏è ƒê√£ chia th√†nh {len(splitted_docs)} chunks")

    # Filter empty chunks
    splitted_docs = [d for d in splitted_docs if len(d["page_content"].strip()) > 50]
    print(f"üîç Sau khi l·ªçc: {len(splitted_docs)} chunks h·ª£p l·ªá")

    report_progress("embedding", 60)

    # ‚úÖ D√πng cache ƒë·ªÉ tr√°nh load model nhi·ªÅu l·∫ßn
    device = "cpu"
    embeddings = embedding_manager.get_model(model_name, device)

    # Create vectorstore
    try:
        vectorstore = FAISS.from_texts(
            [d["page_content"] for d in splitted_docs],
            embeddings,
            metadatas=[d["metadata"] for d in splitted_docs],
        )
    except Exception as e:
        raise ValueError(f"L·ªói khi t·∫°o vectorstore: {str(e)}")

    report_progress("saving", 80)

    # Save vectorstore
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    # S·ª≠ d·ª•ng output_dir n·∫øu c√≥, n·∫øu kh√¥ng d√πng default
    vectorstores_dir = output_dir or DEFAULT_VECTORSTORES_DIR
    os.makedirs(vectorstores_dir, exist_ok=True)

    base_name = os.path.splitext(os.path.basename(pdf_path))[0]
    vs_name = f"vs_{base_name}_{timestamp}"
    save_path = os.path.join(vectorstores_dir, vs_name)

    vectorstore.save_local(save_path)
    print(f"üíæ Vectorstore ƒë√£ l∆∞u t·∫°i: {save_path}")

    # Save metadata to MongoDB
    client = MongoClient(mongo_uri)
    db = client["interviewer_ai"]
    collection = db["vectorstores"]
    # === Chu·∫©n h√≥a ƒë∆∞·ªùng d·∫´n PDF ƒë·ªÉ l∆∞u v√†o DB ===
    try:
        relative_pdf_path = os.path.relpath(pdf_path, Config.BASE_DIR).replace("\\", "/")
    except Exception:
        relative_pdf_path = pdf_path  # fallback n·∫øu c√≥ l·ªói
    pdf_path = relative_pdf_path
    metadata = {
        "pdf_file": os.path.basename(pdf_path),
        "num_pages":len(pages),
        "pdf_path": pdf_path,
        "file_hash": file_hash,
        "file_size_mb": os.path.getsize(pdf_path) / (1024 * 1024),
        "model_name": model_name,
        "model_info": VALID_MODELS[model_name],
        "chunk_size": chunk_size,
        "chunk_overlap": chunk_overlap,
        "splitter_strategy": splitter_strategy,
        "num_chunks": len(splitted_docs),
        "vectorstore_name": vs_name,
        "vectorstore_path": save_path,
        "created_at": datetime.utcnow(),
        "status": "active"
    }

    # Add custom metadata
    if custom_metadata:
        metadata["custom"] = custom_metadata
    metadata["user_id"] = custom_metadata.get("user_id")

    result = collection.insert_one(metadata)
    metadata["_id"] = str(result.inserted_id)

    print(f"‚úÖ Metadata ƒë√£ l∆∞u v√†o MongoDB: {metadata['_id']}")

    report_progress("completed", 100)

    return save_path, metadata


# ======================
# Utility: List vectorstores
# ======================
def list_vectorstores(mongo_uri: str = "mongodb://localhost:27017/") -> List[Dict]:
    """L·∫•y danh s√°ch t·∫•t c·∫£ vectorstores"""
    client = MongoClient(mongo_uri)
    db = client["interviewer_ai"]
    collection = db["vectorstores"]

    vectorstores = list(collection.find({"status": "active"}).sort("created_at", -1))

    for vs in vectorstores:
        vs["_id"] = str(vs["_id"])

    return vectorstores


# ======================
# Utility: Delete vectorstore
# ======================
def delete_vectorstore(
        vectorstore_id: str,
        mongo_uri: str = "mongodb://localhost:27017/",
        remove_files: bool = True
) -> bool:
    """X√≥a ho√†n to√†n vectorstore kh·ªèi DB v√† h·ªá th·ªëng file"""
    from bson import ObjectId
    import shutil

    client = MongoClient(mongo_uri)
    db = client["interviewer_ai"]
    collection = db["vectorstores"]

    vs = collection.find_one({"_id": ObjectId(vectorstore_id)})
    if not vs:
        print(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y vectorstore {vectorstore_id}")
        return False

    # ‚úÖ X√≥a file tr√™n ·ªï ƒëƒ©a n·∫øu c√≥
    if remove_files and os.path.exists(vs["vectorstore_path"]):
        shutil.rmtree(vs["vectorstore_path"], ignore_errors=True)
        print(f"üóëÔ∏è ƒê√£ x√≥a files t·∫°i: {vs['vectorstore_path']}")
    else:
        print(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c vectorstore: {vs['vectorstore_path']}")

    # ‚úÖ X√≥a b·∫£n ghi kh·ªèi MongoDB
    result = collection.delete_one({"_id": ObjectId(vectorstore_id)})
    if result.deleted_count > 0:
        print(f"‚úÖ ƒê√£ x√≥a b·∫£n ghi vectorstore {vectorstore_id} kh·ªèi MongoDB")
        return True
    else:
        print(f"‚ö†Ô∏è Kh√¥ng x√≥a ƒë∆∞·ª£c b·∫£n ghi {vectorstore_id}")
        return False



# ======================
# Example usage
# ======================
if __name__ == "__main__":
    pdf_file = "example.pdf"

    if os.path.exists(pdf_file):
        save_path, metadata = build_vectorstore(
            pdf_path=pdf_file,
            chunk_size=1600,
            chunk_overlap=400,
            model_name="intfloat/multilingual-e5-large-instruct",
            splitter_strategy="nltk",
            skip_duplicate=True,
            custom_metadata={"category": "java", "topic": "advanced"}
        )

        print("\n" + "=" * 50)
        print("Vectorstore ƒë√£ ƒë∆∞·ª£c t·∫°o th√†nh c√¥ng!")
        print(f"Path: {save_path}")
        print(f"Metadata ID: {metadata['_id']}")
    else:
        print(f"File {pdf_file} kh√¥ng t·ªìn t·∫°i")